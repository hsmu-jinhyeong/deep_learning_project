{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1TSMy2p33OOHEqFvj1Gkl6Oa4VtYNCqI-",
      "authorship_tag": "ABX9TyOhGdyGsbgItkd0N3JbsqVf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsmu-jinhyeong/deep_learning_project/blob/main/mbti_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hJwGpXJvOtHW",
        "outputId": "47b5b3dc-160e-432d-fc54-99ccbd21ab22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So91i-ZAaFdM",
        "outputId": "8412dd9d-995e-4af4-b434-b513e9363bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               posts  type\n",
            "0  know intj tool use interaction people excuse a...  INTJ\n",
            "1  rap music ehh opp yeah know valid well know fa...  INTJ\n",
            "2  preferably p hd low except wew lad video p min...  INTJ\n",
            "3  drink like wish could drink red wine give head...  INTJ\n",
            "4  space program ah bad deal meing freelance max ...  INTJ\n",
            "   Unnamed: 0                                               text label\n",
            "0           0  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj\n",
            "1           1  @Hispanthicckk Being you makes you look cute||...  intj\n",
            "2           2  @Alshymi Les balles sont réelles et sont tirée...  intj\n",
            "3           3  I'm like entp but idiotic|||Hey boy, do you wa...  intj\n",
            "4           4  @kaeshurr1 Give it to @ZargarShanif ... He has...  intj\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "reddit_df = pd.read_csv(\"/content/drive/MyDrive/2025-1/dl/dl project /MBTI 500.csv\")\n",
        "twitter_df = pd.read_csv(\"/content/drive/MyDrive/2025-1/dl/dl project /twitter_MBTI.csv\")\n",
        "\n",
        "# 데이터 확인\n",
        "print(reddit_df.head())\n",
        "print(twitter_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reddit_df.columns)\n",
        "print(twitter_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOU1S6k06Bev",
        "outputId": "d1b558cd-e981-42b0-cf71-213ec0cd4d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['posts', 'type'], dtype='object')\n",
            "Index(['Unnamed: 0', 'text', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리\n",
        "!pip install transformers datasets scikit-learn --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "# 1. 데이터 로드\n",
        "reddit_df = pd.read_csv(\"/content/drive/MyDrive/2025-1/dl/dl project /MBTI 500.csv\")\n",
        "twitter_df = pd.read_csv(\"/content/drive/MyDrive/2025-1/dl/dl project /twitter_MBTI.csv\")\n",
        "\n",
        "# 2. 열 이름 정리 및 통일\n",
        "reddit_df = reddit_df.rename(columns={\"posts\": \"text\", \"type\": \"label\"})\n",
        "twitter_df = twitter_df.rename(columns={\"text\": \"text\", \"label\": \"label\"})\n",
        "\n",
        "# 3. 소문자 처리 및 데이터 합치기\n",
        "reddit_df['label'] = reddit_df['label'].str.lower()\n",
        "twitter_df['label'] = twitter_df['label'].str.lower()\n",
        "combined_df = pd.concat([reddit_df[['text', 'label']], twitter_df[['text', 'label']]])\n",
        "combined_df = combined_df.dropna(subset=[\"text\", \"label\"])\n",
        "\n",
        "# 4. 클래스 균형 맞추기 (undersampling)\n",
        "min_count = combined_df['label'].value_counts().min()\n",
        "balanced_df = pd.concat([\n",
        "    resample(df, replace=False, n_samples=min_count, random_state=42)\n",
        "    for label, df in combined_df.groupby(\"label\")\n",
        "])\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 5. 토크나이저 준비\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# 6. 라벨 인코딩\n",
        "labels = balanced_df[\"label\"].tolist()\n",
        "label_to_id = {label: idx for idx, label in enumerate(sorted(set(labels)))}\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "encoded_labels = [label_to_id[label] for label in labels]\n",
        "\n",
        "# 7. 데이터 분할\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    balanced_df[\"text\"].tolist(), encoded_labels, test_size=0.2, stratify=encoded_labels, random_state=42\n",
        ")\n",
        "\n",
        "# 8. 텍스트 토크나이징\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# 9. PyTorch Dataset 정의\n",
        "class MBTIDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = MBTIDataset(train_encodings, train_labels)\n",
        "val_dataset = MBTIDataset(val_encodings, val_labels)\n",
        "\n",
        "# 10. BERT 분류 모델 정의\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_to_id))\n",
        "\n",
        "\n",
        "\n",
        "# 11. 학습 파라미터 정의\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate = 2e-5,\n",
        "    num_train_epochs=10,  # 최대 에포크 수 (early stopping 때문에 여유 있게 줘도 됨)\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,  # 가장 좋은 모델 저장\n",
        "    metric_for_best_model=\"eval_loss\",  # 기준이 될 metric (eval_accuracy도 가능)\n",
        "    greater_is_better=False  # loss는 낮을수록 좋음\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 12. Trainer 정의\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # 2 에포크 연속으로 나빠지면 중단\n",
        ")\n",
        "\n",
        "# 13. 모델 학습\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "vJHVM0c95dxa",
        "outputId": "9be79e82-048a-484f-beaf-2f4896b28b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2290' max='4580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2290/4580 36:22 < 36:24, 1.05 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.527000</td>\n",
              "      <td>2.089630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.772500</td>\n",
              "      <td>1.547514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.411200</td>\n",
              "      <td>1.454226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.223200</td>\n",
              "      <td>1.474138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.080200</td>\n",
              "      <td>1.517419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2290, training_loss=1.6028160928118176, metrics={'train_runtime': 2185.037, 'train_samples_per_second': 16.75, 'train_steps_per_second': 2.096, 'total_flos': 4815537551769600.0, 'train_loss': 1.6028160928118176, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch\tTraining Loss\tValidation Loss ( epoch = 5, learning rate = 2e- 5)\n",
        "\n",
        "\n",
        "1\t2.533000\t2.194306\n",
        "\n",
        "2\t1.856900\t1.593964\n",
        "\n",
        "3\t1.445100\t1.478045\n",
        "\n",
        "4\t1.212600\t1.446583\n",
        "\n",
        "5\t1.066600\t1.439478"
      ],
      "metadata": {
        "id": "rDIcrFVUgNvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 예측 결과 얻기\n",
        "predictions = trainer.predict(val_dataset)\n",
        "\n",
        "# logits → 예측 클래스 ID로 변환\n",
        "preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(val_labels, preds)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UBPxp5w7Opke",
        "outputId": "2760e0e7-b721-471f-c5aa-b4479eb6762e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor 값을 int로 변환하여 KeyError 방지\n",
        "decoded_preds = [id_to_label[int(p)] for p in preds]\n",
        "decoded_labels = [id_to_label[int(l)] for l in val_labels]\n",
        "\n",
        "# 예시 10개 출력\n",
        "for i in range(10):\n",
        "    print(f\"[TEXT] {val_texts[i][:100]}...\")\n",
        "    print(f\"[REAL] {decoded_labels[i]} / [PRED] {decoded_preds[i]}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09NOtBWFOs-a",
        "outputId": "d0952b36-3207-4195-ffbd-6d293654d34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEXT] terrify angry scream calm steadily kind turn psychopath quite literally also scar rarely get angry i...\n",
            "[REAL] istj / [PRED] istj\n",
            "--------------------------------------------------\n",
            "[TEXT] fps league starcraft limit amount possibility possible si prep prepare literally every possibility a...\n",
            "[REAL] isfp / [PRED] isfp\n",
            "--------------------------------------------------\n",
            "[TEXT] chorus carry vein often find ground bring back reality feel bite stimulate luckily know thing satiat...\n",
            "[REAL] isfp / [PRED] isfp\n",
            "--------------------------------------------------\n",
            "[TEXT] set interest maybe could buy help add fund medical bill nadala dami daw niya effort pero walng napal...\n",
            "[REAL] infj / [PRED] infj\n",
            "--------------------------------------------------\n",
            "[TEXT] go away oh god honey imp wristed hit shoulder insu man big cock like hudder go world tbh lot mbti sc...\n",
            "[REAL] entj / [PRED] entj\n",
            "--------------------------------------------------\n",
            "[TEXT] right fi would come say particular situation generally speak heahy fi user value everyone consider g...\n",
            "[REAL] intp / [PRED] esfj\n",
            "--------------------------------------------------\n",
            "[TEXT] also shield stress enough open everyone people take advantage trust feel judge whether vibe come per...\n",
            "[REAL] infj / [PRED] enfp\n",
            "--------------------------------------------------\n",
            "[TEXT] virtue edit reason exact quote book call prophet chapter quote locate call talk link chapter actual ...\n",
            "[REAL] istj / [PRED] istp\n",
            "--------------------------------------------------\n",
            "[TEXT] @distressedrats oh its done when u actually use this pic|||3 people followed me // automatically che...\n",
            "[REAL] enfj / [PRED] esfj\n",
            "--------------------------------------------------\n",
            "[TEXT] intuitive personally type child young absolutely agree know young infant see definite personality fo...\n",
            "[REAL] enfp / [PRED] enfp\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./bert_mbti_model\")\n",
        "tokenizer.save_pretrained(\"./bert_mbti_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peL1OJ4VjojR",
        "outputId": "c5444f94-b9e5-40a7-c510-0c49627b89bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./bert_mbti_model/tokenizer_config.json',\n",
              " './bert_mbti_model/special_tokens_map.json',\n",
              " './bert_mbti_model/vocab.txt',\n",
              " './bert_mbti_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spotipy"
      ],
      "metadata": {
        "id": "QssMwD8Xydi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "# 1. Spotify API 인증\n",
        "client_id = \"9d2c224497d54b5b8ed758c39c8190e3\"\n",
        "client_secret = \"22c02013960e4d338013937ded394671\"\n",
        "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
        "\n",
        "# 2. MBTI → 키워드 매핑 (원하는 대로 수정 가능)\n",
        "mbti_keywords = {\n",
        "    \"intj\": \"instrumental\",\n",
        "    \"intp\": \"experimental\",\n",
        "    \"infj\": \"indie\",\n",
        "    \"infp\": \"acoustic\",\n",
        "    \"entj\": \"rock\",\n",
        "    \"entp\": \"hip hop\",\n",
        "    \"enfj\": \"pop\",\n",
        "    \"enfp\": \"dance\",\n",
        "    \"istj\": \"classical\",\n",
        "    \"isfj\": \"lofi\",\n",
        "    \"istp\": \"techno\",\n",
        "    \"isfp\": \"ambient\",\n",
        "    \"estj\": \"metal\",\n",
        "    \"esfj\": \"kpop\",\n",
        "    \"estp\": \"edm\",\n",
        "    \"esfp\": \"rnb\"\n",
        "}\n",
        "\n",
        "# 3. 예측된 MBTI 하나 선택 (예: \"enfp\"로 가정)\n",
        "predicted_mbti = \"enfp\"\n",
        "search_query = mbti_keywords.get(predicted_mbti.lower(), \"pop\")  # fallback to pop\n",
        "\n",
        "# 4. Spotify에서 검색\n",
        "results = sp.search(q=f\"genre:{search_query}\", type=\"track\", limit=5)\n",
        "\n",
        "# 5. 결과 출력\n",
        "for i, track in enumerate(results['tracks']['items']):\n",
        "    name = track['name']\n",
        "    artist = track['artists'][0]['name']\n",
        "    url = track['external_urls']['spotify']\n",
        "    print(f\"{i+1}. {name} - {artist}\\n   ▶ {url}\")\n"
      ],
      "metadata": {
        "id": "nCLXOmTA3RPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install transformers datasets scikit-learn spotipy --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from spotipy import Spotify\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "# 1. Spotify API 인증 정보 설정\n",
        "client_id = \"9d2c224497d54b5b8ed758c39c8190e3\"\n",
        "client_secret = \"22c02013960e4d338013937ded394671\"\n",
        "sp = Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
        "\n",
        "# 2. MBTI → 키워드 매핑 사전\n",
        "mbti_keywords = {\n",
        "    \"intj\": \"instrumental\",\n",
        "    \"intp\": \"experimental\",\n",
        "    \"infj\": \"indie\",\n",
        "    \"infp\": \"acoustic\",\n",
        "    \"entj\": \"rock\",\n",
        "    \"entp\": \"hip hop\",\n",
        "    \"enfj\": \"pop\",\n",
        "    \"enfp\": \"dance\",\n",
        "    \"istj\": \"classical\",\n",
        "    \"isfj\": \"lofi\",\n",
        "    \"istp\": \"techno\",\n",
        "    \"isfp\": \"ambient\",\n",
        "    \"estj\": \"metal\",\n",
        "    \"esfj\": \"kpop\",\n",
        "    \"estp\": \"edm\",\n",
        "    \"esfp\": \"rnb\"\n",
        "}\n",
        "\n",
        "# 3. BERT 모델과 토크나이저 로드 (본인의 학습된 모델 경로에 맞게 수정)\n",
        "model_path = \"/content/bert_mbti_model\"  # 예시 경로\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# 4. 라벨 id -> 문자열 매핑 (훈련 시 사용한 id_to_label 예시)\n",
        "id_to_label = {\n",
        "    0: \"intj\",\n",
        "    1: \"intp\",\n",
        "    2: \"infj\",\n",
        "    3: \"infp\",\n",
        "    4: \"entj\",\n",
        "    5: \"entp\",\n",
        "    6: \"enfj\",\n",
        "    7: \"enfp\",\n",
        "    8: \"istj\",\n",
        "    9: \"isfj\",\n",
        "    10: \"istp\",\n",
        "    11: \"isfp\",\n",
        "    12: \"estj\",\n",
        "    13: \"esfj\",\n",
        "    14: \"estp\",\n",
        "    15: \"esfp\"\n",
        "}\n",
        "\n",
        "# 5. 텍스트를 받아 MBTI 예측 함수\n",
        "def predict_mbti(text, tokenizer, model, id_to_label):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "    pred_id = torch.argmax(logits, dim=1).item()\n",
        "    pred_label = id_to_label[pred_id]\n",
        "    return pred_label\n",
        "\n",
        "# 6. MBTI로 음악 추천 함수\n",
        "def recommend_music_by_mbti(predicted_mbti, sp, mbti_keywords):\n",
        "    search_query = mbti_keywords.get(predicted_mbti.lower(), \"pop\")\n",
        "    results = sp.search(q=f\"genre:{search_query}\", type=\"track\", limit=5)\n",
        "    print(f\"\\n[MBTI: {predicted_mbti}] 장르 키워드: '{search_query}' 에 맞는 음악 추천입니다.\\n\")\n",
        "    for i, track in enumerate(results['tracks']['items']):\n",
        "        name = track['name']\n",
        "        artist = track['artists'][0]['name']\n",
        "        url = track['external_urls']['spotify']\n",
        "        print(f\"{i+1}. {name} - {artist}\\n   ▶ {url}\")\n",
        "\n",
        "# 7. 메인 함수 (입력 → 예측 → 추천)\n",
        "def main():\n",
        "    user_text = input(\"텍스트를 입력하세요 (MBTI 예측 및 음악 추천):\\n\")\n",
        "    predicted_mbti = predict_mbti(user_text, tokenizer, model, id_to_label)\n",
        "    recommend_music_by_mbti(predicted_mbti, sp, mbti_keywords)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9EMxxcliw3L",
        "outputId": "43cb143b-41cc-4a61-8ded-25e10762d5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텍스트를 입력하세요 (MBTI 예측 및 음악 추천):\n",
            "나는 전화오는게 싫어\n",
            "\n",
            "[MBTI: istp] 장르 키워드: 'techno' 에 맞는 음악 추천입니다.\n",
            "\n",
            "1. Clarity - Zedd\n",
            "   ▶ https://open.spotify.com/track/60wwxj6Dd9NJlirf84wr2c\n",
            "2. The Middle - Zedd\n",
            "   ▶ https://open.spotify.com/track/09IStsImFySgyp0pIQdqAc\n",
            "3. Stay - Zedd\n",
            "   ▶ https://open.spotify.com/track/6uBhi9gBXWjanegOb2Phh0\n",
            "4. Everytime We Touch - Cascada\n",
            "   ▶ https://open.spotify.com/track/5YJtMNWKe55yr49cyJgxva\n",
            "5. Stay The Night - Featuring Hayley Williams Of Paramore - Zedd\n",
            "   ▶ https://open.spotify.com/track/2QtJA4gbwe1AcanB2p21aP\n"
          ]
        }
      ]
    }
  ]
}
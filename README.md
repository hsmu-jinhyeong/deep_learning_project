# deep_learning_project

## 프로젝트의 주제
텍스트를 입력받고 MBTI 예측 및 유형 별 음악 추천 

## 선택 이유
음악을 추천받거나 유형 별로 어떤 음악을 좋아하는지, 타입 별로 좋아하는 음악들의 장르가 비슷한지 알아가고 싶어서

## 모델 설명
### BERT
전이학습 모델 
구글의 Devlin(2018)이 제안한 BERT는 사전 학습된 대용량의 레이블링 되지 않는(unlabeled) 데이터를 이용하여 언어 모델(Language Model)을 학습하고 이를 토대로 특정 작업( 문서 분류, 질의응답, 번역 등)을 위한 신경망을 추가하는 전이 학습 방법입니다.

사전 학습 모델
 대용량의 데이터를 직접 학습시키기 위해서는 매우 많은 자원과 시간이 필요하지만 BERT 모델은 기본적으로 대량의 단어 임베딩 등에 대해 사전 학습이 되어 있는 모델을 제공하기 때문에 상대적으로 적은 자원만으로도 충분히 자연어 처리의 여러 일을 수행할 수 있습니다.

이전에는 단어 임베딩을 위해 Word2Vec, Glove, Fasttext 방식을 사용했지만, BERT가 자연어 처리 분야의 11개 실험에서 가장 좋은 성능을 차지하면서 많이 사용되고 있습니다.

## 데이터셋 정보 

### 성격 유형 별 텍스트
https://www.kaggle.com/datasets/zeyadkhalid/mbti-personality-types-500-dataset

약 10만 6천 건의 전처리된 게시물과 게시자의 성격 유형이 포함되어 있습니다. 각 샘플은 500단어로 동일한 크기로 구성되어 있습니다.

Reddit과 PersonalityCafe 포럼의 게시물을 통해 수집하였으며 각 레코드에는 해당 사용자가 작성한 마지막 50개의 게시물이 포함되어 있습니다.

https://www.kaggle.com/datasets/mazlumi/mbti-personality-type-twitter-dataset

이 데이터셋에는 7800개 이상의 행이 포함되어 있으며, 각 행에는 사용자의 다음과 같은 정보가 있습니다

• Type (해당 사람의 4글자 MBTI 코드/유형)
• 각 항목은 "|||" (파이프 문자 3개)로 구분됩니다.

데이터셋은 TwitterAPI를 통해 얻었습니다. 사용자를 라벨링하기 위해 "나는 ...이다", "내 MBTI는 ..." 및 "나의 성격 유형은 ..."과 같은 검색 구문을 사용했습니다. 그런 다음 모든 성격 유형에 대해 TwitterAPI 쿼리를 통해 데이터를 수집했습니다.

데이터의 품질을 보장하기 위해 200단어 이상을 공유한 사용자만 데이터셋에 포함되었습니다.

### 스포티파이 크롤링

유튜브 뮤직이나 다른 음악 스트리밍 플랫폼을 통해 다양한 정보 수집



# MBTI 텍스트 분류 및 음악 추천 딥러닝 프로젝트 보고서 20201708 김진형 발표 X

## 1. 프로젝트 소개

이 프로젝트는 SNS나 다양한 텍스트를 분석하여, 입력된 텍스트를 작성한 사람의 MBTI를 예측하는 딥러닝 모델을 만드는 것을 목표로 합니다. 예측된 MBTI를 바탕으로 음악을 추천하는 기능도 포함되어 있습니다.

MBTI는 최근 많은 관심을 받고 있으며, 사람들의 성격을 쉽게 분류하고 이해할 수 있는 도구로 널리 활용되고 있습니다. 본 프로젝트는 이러한 트렌드를 반영하여, 사용자에게 재미있고 색다른 방식으로 음악을 추천할 수 있는 서비스를 제안합니다. SNS나 웹사이트에서 제공되는 십자말풀이처럼, 가볍고 흥미롭게 즐길 수 있는 실생활 적용이 가능합니다.

## 2. 주제 관련 배경

MBTI(Myers-Briggs Type Indicator)는 개인의 성격 유형을 16가지로 분류하는 성격 유형 지표입니다. 이는 Carl Jung의 심리유형 이론을 기반으로 만들어졌으며, 외향성/내향성(E/I), 감각형/직관형(S/N), 사고형/감정형(T/F), 판단형/인식형(J/P)의 네 가지 지표를 조합해 성격을 분류합니다.

최근 몇 년간 MBTI는 SNS를 통해 급속도로 확산되었으며, 사람들은 자신의 성격유형을 테스트하고 공유하며 타인과 비교하는 데 큰 흥미를 느끼고 있습니다. 이와 같은 흐름은 데이터 기반 성격 예측 모델 개발에도 큰 관심을 이끌어내고 있습니다.

## 3. 데이터셋 소개

### Reddit MBTI 데이터셋 ([출처](https://www.kaggle.com/datasets/zeyadkhalid/mbti-personality-types-500-dataset))

* 약 10만 6천 개의 전처리된 게시물 포함
* 각 샘플은 동일한 500단어 길이로 구성됨
* Reddit과 PersonalityCafe 포럼 게시글을 수집
* 각 레코드는 해당 사용자의 최근 50개 게시물로 구성됨

### Twitter MBTI 데이터셋 ([출처](https://www.kaggle.com/datasets/mazlumi/mbti-personality-type-twitter-dataset))

* 총 7800개 이상의 샘플
* 각 샘플에는 텍스트와 MBTI 타입 라벨 포함
* Twitter API를 사용해 "나는 ...이다", "내 MBTI는 ..." 등의 문장을 기반으로 데이터 수집
* 최소 200단어 이상을 공유한 사용자만 포함시켜 데이터 품질 확보

두 데이터셋 모두 실제 유저들의 자발적인 텍스트 기반이므로, 자연스러운 언어 패턴을 포함하고 있어 성격 예측 모델 학습에 적합합니다.

## 4. 전처리 과정

* Reddit 데이터셋의 컬럼명을 Twitter 데이터셋과 일치시키기 위해 `posts`를 `text`, `type`을 `label`로 변경
* 모든 라벨을 소문자로 통일
* 두 데이터셋을 결합하고 결측치 제거
* 클래스 불균형을 해결하기 위해 undersampling 적용 (최소 클래스 수 기준으로 균형 맞춤)
* `bert-base-multilingual-cased` 토크나이저를 사용하여 텍스트 토큰화
* `train_test_split`을 통해 학습/검증 데이터셋 8:2 비율로 분할

## 5. 모델 구조

* 모델: `bert-base-multilingual-cased`

  * 사전학습된 다국어 BERT 모델 사용
  * 분류 헤드로 Dense layer 추가하여 MBTI 16가지 유형 분류
* 학습 방식: Hugging Face `Trainer` API 활용
* 주요 설정:

  * 배치 사이즈: 8
  * 러닝 레이트: 2e-5
  * 에포크 수: 최대 10 (Early Stopping 적용)
  * EarlyStoppingCallback: 연속 2회 성능 저하 시 조기 중단
* 런타임: Google Colab T4 GPU 사용

## 6. 참고한 레퍼런스 및 개선점

### 참고 프로젝트:

* [Dacon 코드셰어: MBTI 분류](https://dacon.io/codeshare/4576?dtype=recent)

### 개선점:

* 기존 프로젝트는 다국어 모델을 사용하지 않아 비영어 데이터의 성능에 제약
* 본 프로젝트는 `bert-base-multilingual-cased`를 활용하여 다양한 언어 텍스트 대응 가능
* 클래스 불균형에 대한 명확한 보정 절차(undersampling)를 통해 학습 효율 개선
* `Trainer` API 및 Early Stopping으로 모델 학습 안정성 확보

## 7. 프로젝트 결과

### 학습 로그:

```
Epoch	Training Loss	Validation Loss
1	2.527000	2.089630
2	1.772500	1.547514
3	1.411200	1.454226
4	1.223200	1.474138
5	1.080200	1.517419
```

### 최종 성능:

* Training Loss: **1.6028**
* Validation Accuracy: **0.5841** (약 58.41%)

이는 16개 클래스를 예측하는 다중 분류 문제에서, 단순 추정보다 훨씬 높은 정확도를 보여주며, 실제 사용 가능한 수준의 성능을 입증합니다.

추후 데이터 추가확보와 입력하는 텍스트의 질이 올라갈수록 정확도가 더 높은 경향을 보임.

## 8. 추후 발전 방향

### 보완할 점:

* 학습 데이터 수를 늘려 모델 일반화 성능 향상
* undersampling 대신 oversampling(SMOTE 등) 또는 class-weight 적용 방식 실험
* 텍스트 이외의 정보(시간대, 게시 빈도 등 메타데이터) 활용 가능성 탐색

### 응용 방향:

* 음악 추천 외에도 영화, 드라마, 웹툰 등 다양한 콘텐츠 추천에 응용 가능
* 챗봇, 맞춤형 광고, 감정 분석 기반 서비스 등과 연계
* 웹앱 형태로 배포하여 사용자가 텍스트를 입력하고 추천 결과를 실시간 확인할 수 있도록 구현
